<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Samarth Marudheri</title>
    <link>https://Samarth2506.github.io/projects/</link>
      <atom:link href="https://Samarth2506.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy 2020</copyright><lastBuildDate>Wed, 27 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Projects</title>
      <link>https://Samarth2506.github.io/projects/</link>
    </image>
    
    <item>
      <title>DeepFake Detection with GANs</title>
      <link>https://Samarth2506.github.io/projects/third_project/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>https://Samarth2506.github.io/projects/third_project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt; : The goal of the study is to detect fake images. An autoencoder is trained adversarially to obtain a latent rich representation of real images. The latent representation is then used to reconstruct an image based on the given input image. We propose a comparative study to test if reconstructed features differ strongly for real and fake images leading to enhanced classification performance. We further argue that adversarially training a classifier (DCGAN) generalizes better on unseen data as compared to CNN based architectures.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;motivation&#34;&gt;&lt;strong&gt;Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Recent advances in Generative Adverserial Networks (GANs) have proved both a boon and a bane for the deep learning community. While GANs have made tremendous progress in their ability to synthesize artificial data, the advancement can be misused to architect adverserial attacks. For example, DeepFakes can affect confirmation bias and have consequences on public opinion. Here is a 
&lt;a href=&#34;https://www.youtube.com/watch?v=cQ54GDm1eL0&amp;amp;feature=youtu.be&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt; of &amp;lsquo;Obama&amp;rsquo; making a speech.&lt;/p&gt;
&lt;p&gt;The technology can be further misused for financial gain and even revenge. For example, the 
&lt;a href=&#34;https://www.theverge.com/2019/6/27/18760896/deepfake-nude-ai-app-women-deepnude-non-consensual-pornography&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Nudes application&lt;/a&gt; renders nudes of women. Scary, isn&amp;rsquo;t it?&lt;/p&gt;
&lt;p&gt;This project demonstrates the potential of using the information learnt by GANs themselves in an effective way to classify images as fake or real.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;data-and-pre-processing&#34;&gt;&lt;strong&gt;Data and Pre-processing&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;For real images, a subset of the CelebA-HQ dataset was used. For fake/synthezed images, a subset of Nvidia&amp;rsquo;s StyleGAN dataset was used.&lt;/p&gt;
&lt;p&gt;For efficient computation, the images were resized to Numpy arrays of [64x64] and trained using Google Colab. The models were implemented in PyTorch.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;general-setup&#34;&gt;&lt;strong&gt;General Setup&lt;/strong&gt;&lt;/h2&gt;
&lt;/br&gt;
&lt;p&gt;&lt;img src=&#34;approaches.jpg&#34; alt=&#34;approaches&#34; title=&#34;something&#34;&gt;&lt;/p&gt;
&lt;!-- *Fig. 1: Something* --&gt;
&lt;!-- &lt;img src=&#34;approaches.jpg&#34; width=&#34;600&#34; height=&#34;400&#34; /&gt; --&gt;
&lt;p&gt;Click here to access the 
&lt;a href=&#34;Detect_DeepFakes_GANs.pdf&#34;&gt;complete paper&lt;/a&gt; and 
&lt;a href=&#34;https://github.com/Samarth2506/DL_Project&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automated Trading Strategy with Reinforcement Learning</title>
      <link>https://Samarth2506.github.io/projects/first_project/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://Samarth2506.github.io/projects/first_project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt; : In the quest for a robust trading strategy capable of navigating the dynamics of a complex environment, Reinforcement Learning algorithms offer significant advantages over traditional Machine Learning techniques. In this paper, we propose multiple deep learning models capable of predicting signals that capture sentiment and major events that affect the stock prices of companies. Signals from the models along with a point estimate from a Time Series models are used as to build a trading agent using a state of the art Actor Critic Reinforcement Learning model. The approach yields a return of 14% average profit on the training data.&lt;/p&gt;
&lt;p&gt;Click here to access the 
&lt;a href=&#34;Technical_Paper.pdf&#34;&gt;complete paper&lt;/a&gt; and 
&lt;a href=&#34;https://github.com/Samarth2506/Learning/tree/master/Projects/Automated%20Trading%20using%20RL&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code here&lt;/a&gt;. Below is an informal summary of the project:&lt;/p&gt;
&lt;/br&gt;
&lt;p&gt;Want to make some money by investing in the right stocks with minimal effort? Well, consider your time here well spent!&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;current-automated-trading-methods&#34;&gt;&lt;strong&gt;Current Automated Trading Methods&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Many (or most) of the work in the domain of automated trading have been in Supervised Learning. Typically, prices are forecast with a neural network model with a set of explanatory variables and then fed in to a training module to make a decision based on a threshold. Learning with explicit labels with the intent of minimization of forecast error does not take in to the full complexity of the problem that a typical trader would be influenced by.
Additionally, the dynamic constraints posed by the environment such as liquidity and transaction costs are hard to model with static labels. The problem is further compounded by the fact that current methods are based on statistical arbitrage that typically perform well only with high frequency trades. Hence, sequential decision making with such models with a wider time frame are limited in their approach.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;enter-reinforcement-learning&#34;&gt;&lt;strong&gt;Enter Reinforcement Learning!&lt;/strong&gt;&lt;/h2&gt;
&lt;/br&gt;
&lt;h3 id=&#34;architecture&#34;&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We use three base models to capture various aspects that affect the stock price of companies. The first model is a textual analysis of 8-K SEC filings of companies that capture the major events in a company such as major leadership change, bankruptcy, etc. that a company is required to file. Investors often use 8-K filings to base their decisions on stocks. Additionally, 8-K filings are categorized in to multiple items that provides additional insight in to the nature of event occured.
The second model is a simple time series forecast using an LSTM model. And finally, we will use sentiment data already tagged on the Stocktwits platform to capture sentiment of the crowd. The signals from all 3 models constitute the state of the Reinforcement Learning model.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;signals.jpg&#34; alt=&#34;signals&#34;&gt;&lt;/p&gt;
&lt;p&gt;The actor critic model, as the name suggests consists if learning two sets of weights typically with different neural networks. The Actor defines the policy or the behaviour of the agent and the critic defines how good the action is which is also known as the value function. In our implementation, the same set of weights are shared for both tasks.&lt;/p&gt;
&lt;p&gt;What exactly are these tasks?&lt;/p&gt;
&lt;p&gt;We are learning the probabilities of the actions as well as true reward value for the action. Consequently, the biggest loss for an action assigned low probability would result in a high reward! Below is the sample behaviour of the trading agent:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;agent_behavior.jpg&#34; alt=&#34;agent_behavior&#34;&gt;&lt;/p&gt;
&lt;p&gt;Finally, we end with a training average profit of 14 percent. We plan to run further experiments to deliver further insights. Stay tuned!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Flight Delay Prediction</title>
      <link>https://Samarth2506.github.io/projects/second_project/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://Samarth2506.github.io/projects/second_project/</guid>
      <description>&lt;p&gt;Predicted flight delays from structured data with attributes like origin and destination city, departure and arrival times,carrier information, passenger count and weather station data of the cities of interest. Iterated through the Data Science pipeline to build Machine Learning models including Logistic Regression, SVM, Decision Trees, Random Forests and Gradient Boosting. The details of the implementation are listed below.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;data-pre-processing&#34;&gt;&lt;strong&gt;Data Pre-processing&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The flight data and the weather station data sets were merged carefully to avoid loss of data and retain accurate information.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Missing information was imputed through Knn Imputation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The target column was derived on the condition that flights were considered delay is they arrived 15 minutes later than the scheduled time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;h2 id=&#34;data-visualization&#34;&gt;&lt;strong&gt;Data Visualization&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Performed univariate, bivariate and multivariate visualizations using data to identify underlying patterns and anamolies in data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Observed an imbalance of 90:10 (on time versus delayed flights) in the target feature.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;h2 id=&#34;feature-engineering&#34;&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Large number of levels in categorical data such as origin/destination cities proved to be a challenge. Binned cities by region such North or South to reduce levels in categorical data.  Another strategy was to keep the highest frequency levels and bin the lower frequency levels in to a sigle category.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New columns such as day of the week, month and year were derived from the date column to investigate a correlation with flight delays with different time intervals using the &lt;em&gt;Group By&lt;/em&gt; function.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;h2 id=&#34;data-modeling&#34;&gt;&lt;strong&gt;Data Modeling&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Built multiple classification models including Logistic Regression, SVM, Decision Trees, Random Forests and Gradient Boosting.&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;h2 id=&#34;analysis-iteration-and-communication&#34;&gt;&lt;strong&gt;Analysis, Iteration and Communication&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Iterated through models using a the most important features infered from models like Decision Trees to reduce computational complexity and over-fitting of the model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Presented trade-off between model interpretation and model accuracy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Developed a deeper understanding of model metrics such as recall, precision and F-1 score&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/br&gt;
&lt;h2 id=&#34;results&#34;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A key challenege in prediction was the imbalance in data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gradient Boosting was the best model that achieved an F-1 score of 70%.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
