<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python | Samarth Marudheri</title>
    <link>https://Samarth2506.github.io/tags/python/</link>
      <atom:link href="https://Samarth2506.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <description>Python</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy 2020</copyright><lastBuildDate>Wed, 27 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://Samarth2506.github.io/img/icon.png</url>
      <title>Python</title>
      <link>https://Samarth2506.github.io/tags/python/</link>
    </image>
    
    <item>
      <title>DeepFake Detection with GANs</title>
      <link>https://Samarth2506.github.io/projects/third_project/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>https://Samarth2506.github.io/projects/third_project/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt; : The goal of the study is to detect fake images. An autoencoder is trained adversarially to obtain a latent rich representation of real images. The latent representation is then used to reconstruct an image based on the given input image. We propose a comparative study to test if reconstructed features differ strongly for real and fake images leading to enhanced classification performance. We further argue that adversarially training a classifier (DCGAN) generalizes better on unseen data as compared to CNN based architectures.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;motivation&#34;&gt;&lt;strong&gt;Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Recent advances in Generative Adverserial Networks (GANs) have proved both a boon and a bane for the deep learning community. While GANs have made tremendous progress in their ability to synthesize artificial data, the advancement can be misused to architect adverserial attacks. For example, DeepFakes can affect confirmation bias and have consequences on public opinion. Here is a 
&lt;a href=&#34;https://www.youtube.com/watch?v=cQ54GDm1eL0&amp;amp;feature=youtu.be&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt; of &amp;lsquo;Obama&amp;rsquo; making a speech.&lt;/p&gt;
&lt;p&gt;The technology can be further misused for financial gain and even revenge. For example, the 
&lt;a href=&#34;https://www.theverge.com/2019/6/27/18760896/deepfake-nude-ai-app-women-deepnude-non-consensual-pornography&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Nudes application&lt;/a&gt; renders nudes of women. Scary, isn&amp;rsquo;t it?&lt;/p&gt;
&lt;p&gt;This project demonstrates the potential of using the information learnt by GANs themselves in an effective way to classify images as fake or real.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;data-and-pre-processing&#34;&gt;&lt;strong&gt;Data and Pre-processing&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;For real images, a subset of the CelebA-HQ dataset was used. For fake/synthezed images, a subset of Nvidia&amp;rsquo;s StyleGAN dataset was used.&lt;/p&gt;
&lt;p&gt;For efficient computation, the images were resized to Numpy arrays of [64x64] and trained using Google Colab. The models were implemented in PyTorch.&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&#34;general-setup&#34;&gt;&lt;strong&gt;General Setup&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;autogan-training&#34;&gt;&lt;strong&gt;AutoGAN Training&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;AutoGAN.png&#34; alt=&#34;AutoGAN&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Source [Zhang et al., 2019]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The AutoGAN is trained to reconstruct images based on real images from the CelebA dataset. The encoder network outputs a latent representation which is given to the decoder layer to generate images. As a result, the network outputs a reconstructed image for every real image (pair-wise generation).&lt;/p&gt;
&lt;p&gt;An additional variation experimented was using a 1-layer AutoGAN versus 4-layers to test if more complex architectures of AutoGANs can learn better.&lt;/p&gt;
&lt;h3 id=&#34;experiment---1&#34;&gt;&lt;strong&gt;Experiment - 1&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;approaches.jpg&#34; alt=&#34;approaches&#34; title=&#34;approches&#34;&gt;&lt;/p&gt;
&lt;p&gt;In Approach 1, The real and fake images were passed for a simple CNN classification (using the Alexnet architecture). For Approach 2, The real and fake images were first passed to the trained AutoGAN and each result was then passed to Alexnet for the final classification.&lt;/p&gt;
&lt;/br&gt;
&lt;h3 id=&#34;experiment---2&#34;&gt;&lt;strong&gt;Experiment - 2&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;setup-2.png&#34; alt=&#34;approaches&#34; title=&#34;approches&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;experiment---1-performance&#34;&gt;&lt;strong&gt;Experiment - 1 Performance&lt;/strong&gt;&lt;/h3&gt;
&lt;h3 id=&#34;experiment---2-performance&#34;&gt;&lt;strong&gt;Experiment - 2 Performance&lt;/strong&gt;&lt;/h3&gt;
&lt;h2 id=&#34;takeaways&#34;&gt;&lt;strong&gt;Takeaways&lt;/strong&gt;&lt;/h2&gt;
&lt;!-- *Fig. 1: Something* --&gt;
&lt;!-- &lt;img src=&#34;approaches.jpg&#34; width=&#34;600&#34; height=&#34;400&#34; /&gt; --&gt;
&lt;p&gt;Click here to access the 
&lt;a href=&#34;Detect_DeepFakes_GANs.pdf&#34;&gt;complete paper&lt;/a&gt; and 
&lt;a href=&#34;https://github.com/Samarth2506/DL_Project&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Swirlypy - A tool to learn and teach AI</title>
      <link>https://Samarth2506.github.io/projects/fourth_project/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>https://Samarth2506.github.io/projects/fourth_project/</guid>
      <description>&lt;p&gt;I am currently developing Swirypy, an open source Python package for users to learn and teach AI at the Johns Hopkins Data Science Lab. The work is inspired by 
&lt;a href=&#34;https://swirlstats.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Swirl&lt;/a&gt; for R.&lt;/p&gt;
&lt;p&gt;I am adding features to the package for users to write lessons that are scalable and modularized to interoperate seamlessly with Python libraries to enable easy content creation by instructors.&lt;/p&gt;
&lt;p&gt;The project has been exciting and challenging with my first foray in to Python development. Feel free to write to me to know more and stay tuned for more.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting fraudulent insurance claims</title>
      <link>https://Samarth2506.github.io/projects/fifth_project/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://Samarth2506.github.io/projects/fifth_project/</guid>
      <description>&lt;p&gt;The goal of this project is to flag fradulent claims using Computer Vision techniques for an automotive insurance company. The idea is to use misalignment in tables and font changes in the claim as signals to classify insurance claims.&lt;/p&gt;
&lt;/br&gt;
&lt;p&gt;&lt;strong&gt;Table Misalginment&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I am investigating OpenCV techniques to detect contours of tables to detect relative misalignment of tables given a document. Additionally, I am also looking at a Deep Learning approach where I use a pre-trained model to detect table contours as the dataset is small.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Font Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I am also looking at Deep Learning approaches to detect multiple fonts in a document that may correlate with fraudulent claims.&lt;/p&gt;
&lt;p&gt;I cannot share the code as the data proprietary. However, Feel free to get in touch to know more.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
